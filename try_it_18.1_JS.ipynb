{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models and Vectorization Strategies for Text Classification\n",
    "\n",
    "This try-it focuses on weighing the positives and negatives of different estimators and vectorization strategies for a text classification problem.  In order to consider each of these components, you should make use of the `Pipeline` and `GridSearchCV` objects in scikitlearn to try different combinations of vectorizers with different estimators.  For each of these, you also want to use the `.cv_results_` to examine the time for the estimator to fit the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The dataset below is from [kaggle]() and contains a dataset named the \"ColBert Dataset\" created for this [paper](https://arxiv.org/pdf/2004.12765.pdf).  You are to use the text column to classify whether or not the text was humorous.  It is loaded and displayed below.\n",
    "\n",
    "**Note:** The original dataset contains 200K rows of data. It is best to try to use the full dtaset. If the original dataset is too large for your computer, please use the 'dataset-minimal.csv', which has been reduced to 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True\n",
       "3      5 reasons the 2016 election feels so personal  False\n",
       "4  Pasco police shot mexican migrant from behind,...  False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "\n",
    "**Text preprocessing:** As a pre-processing step, perform both `stemming` and `lemmatizing` to normalize your text before classifying. For each technique use both the `CountVectorize`r and `TfidifVectorizer` and use options for stop words and max features to prepare the text data for your estimator.\n",
    "\n",
    "**Classification:** Once you have prepared the text data with stemming lemmatizing techniques, consider `LogisticRegression`, `DecisionTreeClassifier`, and `MultinomialNB` as classification algorithms for the data. Compare their performance in terms of accuracy and speed.\n",
    "\n",
    "Share the results of your best classifier in the form of a table with the best version of each estimator, a dictionary of the best parameters and the best score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding humor column using pandas factorize function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "199995    0\n",
       "199996    1\n",
       "199997    1\n",
       "199998    0\n",
       "199999    1\n",
       "Name: humor, Length: 200000, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['humor'] = pd.factorize(df['humor'])[0]\n",
    "df['humor']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to stem data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    stem = PorterStemmer()\n",
    "    return ' '.join([stem.stem(w) for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_text = df['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         joe biden rule out 2020 bid : 'guy , i 'm not ...\n",
       "1         watch : darvish gave hitter whiplash with slow...\n",
       "2         what do you call a turtl without it shell ? de...\n",
       "3                    5 reason the 2016 elect feel so person\n",
       "4         pasco polic shot mexican migrant from behind ,...\n",
       "                                ...                        \n",
       "199995    conor maynard seamlessli fit old-school r & b ...\n",
       "199996    how to you make holi water ? you boil the hell...\n",
       "199997    how mani optometrist doe it take to screw in a...\n",
       "199998    mcdonald 's will offici kick off all-day break...\n",
       "199999    an irish man walk on the street and ignor a ba...\n",
       "Name: text, Length: 200000, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funciton to Lemmatize text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize    (w) for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_text = df['text'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Joe biden rule out 2020 bid : 'guys , i 'm not...\n",
       "1         Watch : darvish gave hitter whiplash with slow...\n",
       "2         What do you call a turtle without it shell ? d...\n",
       "3               5 reason the 2016 election feel so personal\n",
       "4         Pasco police shot mexican migrant from behind ...\n",
       "                                ...                        \n",
       "199995    Conor maynard seamlessly fit old-school r & b ...\n",
       "199996    How to you make holy water ? you boil the hell...\n",
       "199997    How many optometrist doe it take to screw in a...\n",
       "199998    Mcdonald 's will officially kick off all-day b...\n",
       "199999    An irish man walk on the street and ignores a ...\n",
       "Name: text, Length: 200000, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splittng the data into text train sets for stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stem = stemmed_text\n",
    "y = df['humor']\n",
    "\n",
    "X_stem_train, X_stem_test, y_train, y_test = train_test_split(X_stem, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the data into train and test for lemmantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma = lemma_text\n",
    "y = df['humor']\n",
    "\n",
    "X_lemma_train, X_lemma_test, y_train, y_test = train_test_split(X_lemma, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer + logistic regression for stemming with pipeline and GridsearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_pipe_logi = Pipeline([('vect', CountVectorizer(max_features=1000, stop_words = 'english')),\n",
    "                       ('logi', LogisticRegression(max_iter=1000, solver= 'liblinear', random_state= 42))])\n",
    "\n",
    "params_vect_logi = {'logi__penalty' : ['l1','l2'], \n",
    "                  'logi__C'       : np.logspace(-3,3,7)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score with Logistic Regression on stemmed text and CountVectorizer: 0.841025\n"
     ]
    }
   ],
   "source": [
    "grid_vect_pipe_logi_stem = GridSearchCV(vect_pipe_logi, param_grid = params_vect_logi)\n",
    "grid_vect_pipe_logi_stem.fit(X_stem_train, y_train)\n",
    "test_score_vect_logi_stem = grid_vect_pipe_logi_stem.score(X_stem_test, y_test)\n",
    "\n",
    "print('Test score with Logistic Regression on stemmed text and CountVectorizer:', test_score_vect_logi_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_LR_step:  0.837275\n",
      " \n",
      "cv_results_LR_step:  {'mean_fit_time': array([1.06186023, 1.06010809, 1.04157467, 1.07797341, 1.0865943 ,\n",
      "       1.15008526, 1.07936502, 1.27405901, 1.07435842, 1.43321724,\n",
      "       1.07599201, 1.65512667, 1.07207575, 1.67797041]), 'std_fit_time': array([0.0275226 , 0.01263166, 0.01143579, 0.00506952, 0.01956631,\n",
      "       0.00803853, 0.02010524, 0.03306385, 0.00998632, 0.03460773,\n",
      "       0.00366258, 0.04636879, 0.00532559, 0.04597968]), 'mean_score_time': array([0.23044219, 0.22313571, 0.22480512, 0.22287779, 0.22704682,\n",
      "       0.2224    , 0.22540259, 0.2240026 , 0.22406545, 0.22535434,\n",
      "       0.22527575, 0.2267952 , 0.22439933, 0.22699618]), 'std_score_time': array([0.01225924, 0.00169614, 0.00265604, 0.00184226, 0.00184092,\n",
      "       0.00198335, 0.00188803, 0.00249301, 0.00157104, 0.00201366,\n",
      "       0.0018713 , 0.0041223 , 0.00179024, 0.00387541]), 'param_logi__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0,\n",
      "                   10.0, 100.0, 100.0, 1000.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_logi__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'logi__C': 0.001, 'logi__penalty': 'l1'}, {'logi__C': 0.001, 'logi__penalty': 'l2'}, {'logi__C': 0.01, 'logi__penalty': 'l1'}, {'logi__C': 0.01, 'logi__penalty': 'l2'}, {'logi__C': 0.1, 'logi__penalty': 'l1'}, {'logi__C': 0.1, 'logi__penalty': 'l2'}, {'logi__C': 1.0, 'logi__penalty': 'l1'}, {'logi__C': 1.0, 'logi__penalty': 'l2'}, {'logi__C': 10.0, 'logi__penalty': 'l1'}, {'logi__C': 10.0, 'logi__penalty': 'l2'}, {'logi__C': 100.0, 'logi__penalty': 'l1'}, {'logi__C': 100.0, 'logi__penalty': 'l2'}, {'logi__C': 1000.0, 'logi__penalty': 'l1'}, {'logi__C': 1000.0, 'logi__penalty': 'l2'}], 'split0_test_score': array([0.65359375, 0.782875  , 0.76709375, 0.826     , 0.8374375 ,\n",
      "       0.8386875 , 0.83809375, 0.83853125, 0.8380625 , 0.83821875,\n",
      "       0.8380625 , 0.83809375, 0.83809375, 0.8380625 ]), 'split1_test_score': array([0.65271875, 0.78      , 0.76609375, 0.82278125, 0.83453125,\n",
      "       0.83565625, 0.83671875, 0.83625   , 0.836375  , 0.836375  ,\n",
      "       0.8363125 , 0.8363125 , 0.836375  , 0.83628125]), 'split2_test_score': array([0.6571875 , 0.78446875, 0.76921875, 0.825     , 0.834625  ,\n",
      "       0.83625   , 0.836375  , 0.836875  , 0.83675   , 0.83665625,\n",
      "       0.8365625 , 0.8365625 , 0.8365625 , 0.8365625 ]), 'split3_test_score': array([0.65309375, 0.7795625 , 0.76559375, 0.8228125 , 0.83359375,\n",
      "       0.8345    , 0.83565625, 0.83540625, 0.835625  , 0.83559375,\n",
      "       0.8355625 , 0.8355625 , 0.8355625 , 0.8355625 ]), 'split4_test_score': array([0.6576875 , 0.784375  , 0.77121875, 0.8290625 , 0.837875  ,\n",
      "       0.83903125, 0.83890625, 0.8393125 , 0.83878125, 0.8389375 ,\n",
      "       0.8389375 , 0.8389375 , 0.8389375 , 0.8389375 ]), 'mean_test_score': array([0.65485625, 0.78225625, 0.76784375, 0.82513125, 0.8356125 ,\n",
      "       0.836825  , 0.83715   , 0.837275  , 0.83711875, 0.83715625,\n",
      "       0.8370875 , 0.83709375, 0.83710625, 0.83708125]), 'std_test_score': array([0.00213166, 0.00210305, 0.00209613, 0.0023292 , 0.00171284,\n",
      "       0.0017572 , 0.00118262, 0.00144447, 0.00114673, 0.00123317,\n",
      "       0.00123085, 0.00123586, 0.00122818, 0.00123485]), 'rank_test_score': array([14, 12, 13, 11, 10,  9,  3,  1,  4,  2,  7,  6,  5,  8],\n",
      "      dtype=int32)}\n",
      " \n",
      "get_params_LR_step:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})>\n",
      " \n",
      "predict_proba_LR_step: <function BaseSearchCV.predict_proba at 0x7fa5863a0940>\n",
      " \n",
      "best_params_LR_step : {'logi__C': 1.0, 'logi__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_LR_step: ', grid_vect_pipe_logi_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_LR_step: ', grid_vect_pipe_logi_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_LR_step: ',grid_vect_pipe_logi_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_LR_step:', grid_vect_pipe_logi_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_LR_step :', grid_vect_pipe_logi_stem.best_params_ )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf + logitic regression for stem with pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipe = Pipeline([('tfidf', TfidfVectorizer(max_features= 1000, stop_words= 'english')),\n",
    "                            ('logi', LogisticRegression(max_iter= 1000, solver= 'liblinear' ,random_state= 42))])\n",
    "tfidf_params = {'logi__penalty': ['l1', 'l2'], \n",
    "                'logi__C': np.logspace(-3,3,7) }\n",
    "\n",
    "params_vect_logi = {'logi__penalty' : ['l1','l2'], \n",
    "                  'logi__C'       : np.logspace(-3,3,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score with Logistic Regression on stemmed text and Tfidf: GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_logi_stem = GridSearchCV(tfidf_pipe, param_grid= tfidf_params)\n",
    "grid_tfidf_pipe_logi_stem.fit(X_stem_train, y_train)\n",
    "grid_tfidf_pipe_logi_stem.score(X_stem_test, y_test)\n",
    "print('Test score with Logistic Regression on stemmed text and Tfidf:', grid_tfidf_pipe_logi_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tiidf_logi_step:  0.8403937499999999\n",
      " \n",
      "cv_results_tfidf_logi_step:  {'mean_fit_time': array([1.071351  , 1.04827867, 1.03607264, 1.06717935, 1.11909685,\n",
      "       1.0793622 , 1.08110299, 1.22582564, 1.14199638, 1.31118197,\n",
      "       1.094771  , 1.42250419, 1.07952132, 1.44474163]), 'std_fit_time': array([0.05820728, 0.03760584, 0.04642379, 0.05343631, 0.02502679,\n",
      "       0.02790069, 0.0122472 , 0.05735116, 0.03301738, 0.01948987,\n",
      "       0.03871906, 0.01677982, 0.03343963, 0.0439909 ]), 'mean_score_time': array([0.23536215, 0.22997642, 0.22752261, 0.228864  , 0.23482704,\n",
      "       0.22761226, 0.22490554, 0.23599763, 0.23421283, 0.23959236,\n",
      "       0.2287858 , 0.22676735, 0.22731938, 0.2247602 ]), 'std_score_time': array([0.00675636, 0.00690087, 0.00799636, 0.00919379, 0.01192795,\n",
      "       0.00222562, 0.00225433, 0.01054513, 0.00313514, 0.01082954,\n",
      "       0.00256676, 0.00197121, 0.00232754, 0.00129493]), 'param_logi__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0,\n",
      "                   10.0, 100.0, 100.0, 1000.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_logi__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'logi__C': 0.001, 'logi__penalty': 'l1'}, {'logi__C': 0.001, 'logi__penalty': 'l2'}, {'logi__C': 0.01, 'logi__penalty': 'l1'}, {'logi__C': 0.01, 'logi__penalty': 'l2'}, {'logi__C': 0.1, 'logi__penalty': 'l1'}, {'logi__C': 0.1, 'logi__penalty': 'l2'}, {'logi__C': 1.0, 'logi__penalty': 'l1'}, {'logi__C': 1.0, 'logi__penalty': 'l2'}, {'logi__C': 10.0, 'logi__penalty': 'l1'}, {'logi__C': 10.0, 'logi__penalty': 'l2'}, {'logi__C': 100.0, 'logi__penalty': 'l1'}, {'logi__C': 100.0, 'logi__penalty': 'l2'}, {'logi__C': 1000.0, 'logi__penalty': 'l1'}, {'logi__C': 1000.0, 'logi__penalty': 'l2'}], 'split0_test_score': array([0.5498125 , 0.7885    , 0.73484375, 0.8208125 , 0.835125  ,\n",
      "       0.838125  , 0.839375  , 0.84      , 0.841375  , 0.84171875,\n",
      "       0.8414375 , 0.84146875, 0.8414375 , 0.84146875]), 'split1_test_score': array([0.5510625 , 0.787     , 0.7330625 , 0.8165    , 0.83134375,\n",
      "       0.83453125, 0.8366875 , 0.836125  , 0.8394375 , 0.83946875,\n",
      "       0.8395    , 0.83946875, 0.8395    , 0.8395    ]), 'split2_test_score': array([0.551125  , 0.78921875, 0.73628125, 0.82115625, 0.8325    ,\n",
      "       0.83634375, 0.8399375 , 0.8386875 , 0.839875  , 0.83984375,\n",
      "       0.8398125 , 0.8398125 , 0.8398125 , 0.8398125 ]), 'split3_test_score': array([0.5505625 , 0.787875  , 0.73159375, 0.8185625 , 0.83059375,\n",
      "       0.8339375 , 0.83921875, 0.8369375 , 0.83953125, 0.839375  ,\n",
      "       0.8394375 , 0.8394375 , 0.8394375 , 0.8394375 ]), 'split4_test_score': array([0.5509375 , 0.79246875, 0.73978125, 0.8234375 , 0.83578125,\n",
      "       0.83809375, 0.84009375, 0.8401875 , 0.8415625 , 0.8415625 ,\n",
      "       0.84125   , 0.84128125, 0.84125   , 0.84121875]), 'mean_test_score': array([0.5507    , 0.7890125 , 0.7351125 , 0.82009375, 0.83306875,\n",
      "       0.83620625, 0.8390625 , 0.8383875 , 0.84035625, 0.84039375,\n",
      "       0.8402875 , 0.84029375, 0.8402875 , 0.8402875 ]), 'std_test_score': array([0.00048477, 0.0018759 , 0.00282204, 0.00237006, 0.0020499 ,\n",
      "       0.00174448, 0.00123222, 0.00162182, 0.00092187, 0.00103127,\n",
      "       0.00087375, 0.00089456, 0.00087375, 0.00087531]), 'rank_test_score': array([14, 12, 13, 11, 10,  9,  7,  8,  2,  1,  4,  3,  4,  4],\n",
      "      dtype=int32)}\n",
      " \n",
      "get_params_tfidf_logi_step:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})>\n",
      " \n",
      "predict_proba_tfidf_logi_step: <function BaseSearchCV.predict_proba at 0x7fa550251280>\n",
      " \n",
      "best_params_tfidf_logi_step : {'logi__C': 10.0, 'logi__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tiidf_logi_step: ', grid_tfidf_pipe_logi_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_logi_step: ', grid_tfidf_pipe_logi_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_logi_step: ',grid_tfidf_pipe_logi_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_logi_step:', grid_tfidf_pipe_logi_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf_logi_step :', grid_tfidf_pipe_logi_stem.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer + logistic Rgression for Lemma with pipeline and gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Logistic Regression on lemmantized text + CountVectorizer: 0.83335\n"
     ]
    }
   ],
   "source": [
    "grid_vect_pipe_LR_lemma = GridSearchCV(vect_pipe_logi, param_grid= params_vect_logi)\n",
    "grid_vect_pipe_LR_lemma.fit(X_lemma_train, y_train)\n",
    "vect_lemma_test_score = grid_vect_pipe_LR_lemma.score(X_lemma_test, y_test)\n",
    "\n",
    "print('Test score: Logistic Regression on lemmantized text + CountVectorizer:', vect_lemma_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_LR_lemma:  0.82938125\n",
      " \n",
      "cv_results_LR_lemma:  {'mean_fit_time': array([1.12016058, 1.16496506, 1.12641087, 1.10572138, 1.15072269,\n",
      "       1.22848978, 1.11352658, 1.2592237 , 1.18623304, 1.50994353,\n",
      "       1.14869924, 1.70105386, 1.15777249, 1.62456017]), 'std_fit_time': array([0.04290032, 0.05950973, 0.02105538, 0.03552165, 0.04720622,\n",
      "       0.02813765, 0.01997664, 0.03351569, 0.01753018, 0.02283815,\n",
      "       0.04588849, 0.01898968, 0.02760195, 0.04053697]), 'mean_score_time': array([0.22686148, 0.23654995, 0.22926378, 0.21909175, 0.23059297,\n",
      "       0.22798457, 0.22231565, 0.22562394, 0.23807497, 0.24063506,\n",
      "       0.23033671, 0.23483181, 0.23336053, 0.22638073]), 'std_score_time': array([0.00529059, 0.00801755, 0.00414777, 0.0049074 , 0.00957485,\n",
      "       0.00215392, 0.0028929 , 0.00626409, 0.00521045, 0.01185345,\n",
      "       0.00890224, 0.00819725, 0.00378743, 0.00605415]), 'param_logi__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0,\n",
      "                   10.0, 100.0, 100.0, 1000.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_logi__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'logi__C': 0.001, 'logi__penalty': 'l1'}, {'logi__C': 0.001, 'logi__penalty': 'l2'}, {'logi__C': 0.01, 'logi__penalty': 'l1'}, {'logi__C': 0.01, 'logi__penalty': 'l2'}, {'logi__C': 0.1, 'logi__penalty': 'l1'}, {'logi__C': 0.1, 'logi__penalty': 'l2'}, {'logi__C': 1.0, 'logi__penalty': 'l1'}, {'logi__C': 1.0, 'logi__penalty': 'l2'}, {'logi__C': 10.0, 'logi__penalty': 'l1'}, {'logi__C': 10.0, 'logi__penalty': 'l2'}, {'logi__C': 100.0, 'logi__penalty': 'l1'}, {'logi__C': 100.0, 'logi__penalty': 'l2'}, {'logi__C': 1000.0, 'logi__penalty': 'l1'}, {'logi__C': 1000.0, 'logi__penalty': 'l2'}], 'split0_test_score': array([0.63325   , 0.78053125, 0.75715625, 0.814625  , 0.82596875,\n",
      "       0.82628125, 0.82653125, 0.82653125, 0.82678125, 0.82675   ,\n",
      "       0.8268125 , 0.8268125 , 0.8268125 , 0.8268125 ]), 'split1_test_score': array([0.63428125, 0.779875  , 0.7555    , 0.81534375, 0.825125  ,\n",
      "       0.828375  , 0.82859375, 0.82871875, 0.82878125, 0.828875  ,\n",
      "       0.82878125, 0.8288125 , 0.8286875 , 0.82878125]), 'split2_test_score': array([0.63653125, 0.782625  , 0.7575    , 0.81775   , 0.8263125 ,\n",
      "       0.8285    , 0.83121875, 0.83128125, 0.8314375 , 0.83146875,\n",
      "       0.83146875, 0.8315    , 0.8314375 , 0.8315    ]), 'split3_test_score': array([0.6319375 , 0.77890625, 0.754125  , 0.814625  , 0.825375  ,\n",
      "       0.8275625 , 0.8271875 , 0.82759375, 0.827125  , 0.8273125 ,\n",
      "       0.82734375, 0.827375  , 0.827375  , 0.827375  ]), 'split4_test_score': array([0.636625  , 0.7856875 , 0.75884375, 0.82134375, 0.8299375 ,\n",
      "       0.83203125, 0.8330625 , 0.83253125, 0.83246875, 0.8323125 ,\n",
      "       0.83240625, 0.83240625, 0.83240625, 0.83240625]), 'mean_test_score': array([0.634525  , 0.781525  , 0.756625  , 0.8167375 , 0.82654375,\n",
      "       0.82855   , 0.82931875, 0.82933125, 0.82931875, 0.82934375,\n",
      "       0.8293625 , 0.82938125, 0.82934375, 0.829375  ]), 'std_test_score': array([0.00183386, 0.00241265, 0.00164234, 0.00257335, 0.00174817,\n",
      "       0.00191178, 0.00246835, 0.0022484 , 0.00227824, 0.00220918,\n",
      "       0.00221885, 0.00221751, 0.00221254, 0.00221915]), 'rank_test_score': array([14, 12, 13, 11, 10,  9,  7,  6,  7,  4,  3,  1,  4,  2],\n",
      "      dtype=int32)}\n",
      " \n",
      "get_params_LR_lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})>\n",
      " \n",
      "predict_proba_LR_lemma: <function BaseSearchCV.predict_proba at 0x7fa5502513a0>\n",
      " \n",
      "best_params_LR_lemma : {'logi__C': 100.0, 'logi__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_LR_lemma: ', grid_vect_pipe_LR_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_LR_lemma: ', grid_vect_pipe_LR_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_LR_lemma: ',grid_vect_pipe_LR_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_LR_lemma:', grid_vect_pipe_LR_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_LR_lemma :', grid_vect_pipe_LR_lemma.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf + logitic regression for lemma with pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score with Logistic Regression on lemmantized text and Tfidf: GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_logi_lemma = GridSearchCV(tfidf_pipe, param_grid= tfidf_params)\n",
    "grid_tfidf_pipe_logi_lemma.fit(X_lemma_train, y_train)\n",
    "grid_tfidf_pipe_logi_lemma.score(X_lemma_test, y_test)\n",
    "print('Test score with Logistic Regression on lemmantized text and Tfidf:', grid_tfidf_pipe_logi_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tiidf_logi_lemma:  0.8300749999999999\n",
      " \n",
      "cv_results_tfidf_logi_lemma:  {'mean_fit_time': array([1.03434153, 1.10246758, 1.10015993, 1.11090407, 1.11286507,\n",
      "       1.13320503, 1.11573553, 1.16650319, 1.08843122, 1.26637416,\n",
      "       1.16651363, 1.48363905, 1.19852486, 1.65222397]), 'std_fit_time': array([0.03448356, 0.0261893 , 0.03727306, 0.03504684, 0.01392108,\n",
      "       0.0290086 , 0.02616761, 0.01344687, 0.0337909 , 0.01467346,\n",
      "       0.04579799, 0.04478316, 0.02473891, 0.04716765]), 'mean_score_time': array([0.22808285, 0.240417  , 0.23341742, 0.22666073, 0.22501378,\n",
      "       0.22847419, 0.22395988, 0.22656274, 0.22141452, 0.22190099,\n",
      "       0.22923484, 0.23471313, 0.2309515 , 0.23189378]), 'std_score_time': array([0.01010736, 0.00680846, 0.01076328, 0.00539039, 0.00598951,\n",
      "       0.00746732, 0.00441027, 0.00614214, 0.00067419, 0.00218063,\n",
      "       0.00600055, 0.00973421, 0.00262156, 0.00753103]), 'param_logi__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0,\n",
      "                   10.0, 100.0, 100.0, 1000.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_logi__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'logi__C': 0.001, 'logi__penalty': 'l1'}, {'logi__C': 0.001, 'logi__penalty': 'l2'}, {'logi__C': 0.01, 'logi__penalty': 'l1'}, {'logi__C': 0.01, 'logi__penalty': 'l2'}, {'logi__C': 0.1, 'logi__penalty': 'l1'}, {'logi__C': 0.1, 'logi__penalty': 'l2'}, {'logi__C': 1.0, 'logi__penalty': 'l1'}, {'logi__C': 1.0, 'logi__penalty': 'l2'}, {'logi__C': 10.0, 'logi__penalty': 'l1'}, {'logi__C': 10.0, 'logi__penalty': 'l2'}, {'logi__C': 100.0, 'logi__penalty': 'l1'}, {'logi__C': 100.0, 'logi__penalty': 'l2'}, {'logi__C': 1000.0, 'logi__penalty': 'l1'}, {'logi__C': 1000.0, 'logi__penalty': 'l2'}], 'split0_test_score': array([0.5498125 , 0.79053125, 0.7226875 , 0.811875  , 0.8239375 ,\n",
      "       0.8255625 , 0.82846875, 0.8278125 , 0.8280625 , 0.82803125,\n",
      "       0.828     , 0.82803125, 0.82803125, 0.82803125]), 'split1_test_score': array([0.5510625 , 0.79228125, 0.7216875 , 0.814     , 0.8221875 ,\n",
      "       0.8274375 , 0.8279375 , 0.8290625 , 0.829     , 0.82896875,\n",
      "       0.82903125, 0.82915625, 0.8290625 , 0.8290625 ]), 'split2_test_score': array([0.551125  , 0.7941875 , 0.7245    , 0.815625  , 0.82409375,\n",
      "       0.82825   , 0.8315    , 0.8309375 , 0.83284375, 0.8314375 ,\n",
      "       0.83271875, 0.83275   , 0.83271875, 0.83271875]), 'split3_test_score': array([0.5505625 , 0.79053125, 0.72046875, 0.81175   , 0.8220625 ,\n",
      "       0.82628125, 0.8275    , 0.8278125 , 0.82746875, 0.8275    ,\n",
      "       0.827375  , 0.8273125 , 0.82734375, 0.8273125 ]), 'split4_test_score': array([0.5509375 , 0.7966875 , 0.72734375, 0.8178125 , 0.828375  ,\n",
      "       0.83059375, 0.83259375, 0.8325625 , 0.833     , 0.833125  ,\n",
      "       0.8328125 , 0.832875  , 0.83284375, 0.83284375]), 'mean_test_score': array([0.5507    , 0.79284375, 0.7233375 , 0.8142125 , 0.82413125,\n",
      "       0.827625  , 0.8296    , 0.8296375 , 0.830075  , 0.8298125 ,\n",
      "       0.8299875 , 0.830025  , 0.83      , 0.82999375]), 'std_test_score': array([0.00048477, 0.00234912, 0.00239901, 0.00230339, 0.00228501,\n",
      "       0.00174922, 0.00205067, 0.00185674, 0.00237571, 0.00213755,\n",
      "       0.00232938, 0.00235098, 0.0023362 , 0.00234332]), 'rank_test_score': array([14, 12, 13, 11, 10,  9,  8,  7,  1,  6,  5,  2,  3,  4],\n",
      "      dtype=int32)}\n",
      " \n",
      "get_params_tfidf_logi_lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('logi',\n",
      "                                        LogisticRegression(max_iter=1000,\n",
      "                                                           random_state=42,\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'logi__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
      "                         'logi__penalty': ['l1', 'l2']})>\n",
      " \n",
      "predict_proba_tfidf_logi_lemma: <function BaseSearchCV.predict_proba at 0x7fa550251700>\n",
      " \n",
      "best_params_tfidf_logi_lemma : {'logi__C': 10.0, 'logi__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tiidf_logi_lemma: ', grid_tfidf_pipe_logi_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_logi_lemma: ', grid_tfidf_pipe_logi_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_logi_lemma: ',grid_tfidf_pipe_logi_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_logi_lemma:', grid_tfidf_pipe_logi_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf_logi_lemma :', grid_tfidf_pipe_logi_lemma.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer + Decision Tree on Stemmed text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_pipe_DT = Pipeline([('vect', CountVectorizer(max_features = 1000, stop_words= 'english')),\n",
    "                          ('dtc', DecisionTreeClassifier(random_state= 42))\n",
    "                          ])\n",
    "\n",
    "params_vect_DT = {'dtc__criterion': ['gini', 'entropy', 'log_loss' ] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.7906     0.79761875        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Decision Tree Classifier on Stemmed text + CountVectorizer: 0.795125\n",
      " Best Params for DTC Stemmed text:  {'dtc__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "grid_vect_pipe_DT_stem = GridSearchCV(vect_pipe_DT, param_grid= params_vect_DT)\n",
    "grid_vect_pipe_DT_stem.fit(X_stem_train, y_train)\n",
    "test_score_vect_DT_stem = grid_vect_pipe_DT_stem.score(X_stem_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on Stemmed text + CountVectorizer:', test_score_vect_DT_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_DT_stem:  0.7906000000000001\n",
      " \n",
      "cv_results_DT_stem:  {'mean_fit_time': array([17.94860601, 20.33583522,  1.2809526 ]), 'std_fit_time': array([1.8315248 , 0.1944396 , 0.02366985]), 'mean_score_time': array([0.28974557, 0.33905592, 0.        ]), 'std_score_time': array([0.036345  , 0.01968207, 0.        ]), 'param_dtc__criterion': masked_array(data=['gini', 'entropy', 'log_loss'],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dtc__criterion': 'gini'}, {'dtc__criterion': 'entropy'}, {'dtc__criterion': 'log_loss'}], 'split0_test_score': array([0.78665625, 0.79725   ,        nan]), 'split1_test_score': array([0.7926875 , 0.79909375,        nan]), 'split2_test_score': array([0.792     , 0.79878125,        nan]), 'split3_test_score': array([0.79071875, 0.79746875,        nan]), 'split4_test_score': array([0.7909375, 0.7955   ,       nan]), 'mean_test_score': array([0.7906    , 0.79761875,        nan]), 'std_test_score': array([0.00209756, 0.00127864,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_DT_stem:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('dtc',\n",
      "                                        DecisionTreeClassifier(random_state=42))]),\n",
      "             param_grid={'dtc__criterion': ['gini', 'entropy', 'log_loss']})>\n",
      " \n",
      "predict_proba_DT_stem:  <function BaseSearchCV.predict_proba at 0x7fa4e84ddc10>\n",
      " \n",
      "best_params_DT_stem : {'dtc__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_DT_stem: ', grid_vect_pipe_DT_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_DT_stem: ', grid_vect_pipe_DT_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_DT_stem: ',grid_vect_pipe_DT_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_DT_stem: ', grid_vect_pipe_DT_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_DT_stem :', grid_vect_pipe_DT_stem.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf + Decision Tree on Stemmed text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipe_DT = Pipeline([('tfidf', TfidfVectorizer(max_features = 1000, stop_words= 'english')),\n",
    "                          ('dtc', DecisionTreeClassifier(random_state= 42))\n",
    "                          ])\n",
    "\n",
    "params_tfidf_DT = {'dtc__criterion': ['gini', 'entropy', 'log_loss' ] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.80124375 0.80139375        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Decision Tree Classifier on Stemmed text + Tfidf: 0.795125\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_DT_stem = GridSearchCV(tfidf_pipe_DT, param_grid= params_tfidf_DT)\n",
    "grid_tfidf_pipe_DT_stem.fit(X_stem_train, y_train)\n",
    "test_score_tfidf_DT_stem = grid_vect_pipe_DT_stem.score(X_stem_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on Stemmed text + Tfidf:', test_score_tfidf_DT_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tfidf_DT_stem:  0.80124375\n",
      " \n",
      "cv_results_tfidf_DT_stem:  {'mean_fit_time': array([19.55327625, 19.16711926,  0.96753936]), 'std_fit_time': array([0.36389745, 0.11108896, 0.00573259]), 'mean_score_time': array([0.25955434, 0.24992895, 0.        ]), 'std_score_time': array([0.01153308, 0.00253141, 0.        ]), 'param_dtc__criterion': masked_array(data=['gini', 'entropy', 'log_loss'],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dtc__criterion': 'gini'}, {'dtc__criterion': 'entropy'}, {'dtc__criterion': 'log_loss'}], 'split0_test_score': array([0.7990625 , 0.79915625,        nan]), 'split1_test_score': array([0.80134375, 0.80075   ,        nan]), 'split2_test_score': array([0.80165625, 0.802375  ,        nan]), 'split3_test_score': array([0.80109375, 0.8029375 ,        nan]), 'split4_test_score': array([0.8030625, 0.80175  ,       nan]), 'mean_test_score': array([0.80124375, 0.80139375,        nan]), 'std_test_score': array([0.00128595, 0.0013337 ,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_tfidf_DT_stem:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('dtc',\n",
      "                                        DecisionTreeClassifier(random_state=42))]),\n",
      "             param_grid={'dtc__criterion': ['gini', 'entropy', 'log_loss']})>\n",
      " \n",
      "predict_proba_tfidf_DT_stem:  <function BaseSearchCV.predict_proba at 0x7fa5863a0550>\n",
      " \n",
      "best_params_tfidf_DT_stem:  {'dtc__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tfidf_DT_stem: ', grid_tfidf_pipe_DT_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_DT_stem: ', grid_tfidf_pipe_DT_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_DT_stem: ',grid_tfidf_pipe_DT_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_DT_stem: ', grid_tfidf_pipe_DT_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf_DT_stem: ', grid_tfidf_pipe_DT_stem.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorize + Decision Tree on Lemmatized text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.602275   0.65605625 0.68035    0.60203125 0.65298125 0.67650625\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_vect_pipe_DT_lemma = GridSearchCV(vect_pipe_DT, param_grid= params_vect_DT)\n",
    "grid_vect_pipe_DT_lemma.fit(X_lemma_train, y_train)\n",
    "test_score_vect_DT_lemma = grid_vect_pipe_DT_stem.score(X_lemma_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on Lemmantized text + CountVectorizer:', test_score_vect_DT_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_DT_Lemma:  0.602275\n",
      " \n",
      "cv_results_DT_Lemma:  {'mean_fit_time': array([1.10141706, 1.16836252, 1.27634659, 1.07619867, 1.21876235,\n",
      "       1.40477114, 1.0813302 , 1.06762977, 1.03658552]), 'std_fit_time': array([0.01928752, 0.01724247, 0.02429805, 0.04743374, 0.02181738,\n",
      "       0.03056986, 0.02118325, 0.01355709, 0.01598051]), 'mean_score_time': array([0.2349504 , 0.22671204, 0.22993083, 0.22712793, 0.23590784,\n",
      "       0.23761978, 0.        , 0.        , 0.        ]), 'std_score_time': array([0.00409131, 0.00618552, 0.00639956, 0.00988274, 0.00722432,\n",
      "       0.00523684, 0.        , 0.        , 0.        ]), 'param_dtc__criterion': masked_array(data=['gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'log_loss', 'log_loss', 'log_loss'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dtc__max_depth': masked_array(data=[5, 10, 15, 5, 10, 15, 5, 10, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dtc__criterion': 'gini', 'dtc__max_depth': 5}, {'dtc__criterion': 'gini', 'dtc__max_depth': 10}, {'dtc__criterion': 'gini', 'dtc__max_depth': 15}, {'dtc__criterion': 'entropy', 'dtc__max_depth': 5}, {'dtc__criterion': 'entropy', 'dtc__max_depth': 10}, {'dtc__criterion': 'entropy', 'dtc__max_depth': 15}, {'dtc__criterion': 'log_loss', 'dtc__max_depth': 5}, {'dtc__criterion': 'log_loss', 'dtc__max_depth': 10}, {'dtc__criterion': 'log_loss', 'dtc__max_depth': 15}], 'split0_test_score': array([0.6001875 , 0.65484375, 0.67815625, 0.60009375, 0.6491875 ,\n",
      "       0.67315625,        nan,        nan,        nan]), 'split1_test_score': array([0.6015625 , 0.65496875, 0.67878125, 0.60125   , 0.65040625,\n",
      "       0.67825   ,        nan,        nan,        nan]), 'split2_test_score': array([0.60421875, 0.65890625, 0.683625  , 0.604125  , 0.65415625,\n",
      "       0.67928125,        nan,        nan,        nan]), 'split3_test_score': array([0.600625  , 0.6530625 , 0.677625  , 0.60034375, 0.6529375 ,\n",
      "       0.67321875,        nan,        nan,        nan]), 'split4_test_score': array([0.60478125, 0.6585    , 0.6835625 , 0.60434375, 0.65821875,\n",
      "       0.678625  ,        nan,        nan,        nan]), 'mean_test_score': array([0.602275  , 0.65605625, 0.68035   , 0.60203125, 0.65298125,\n",
      "       0.67650625,        nan,        nan,        nan]), 'std_test_score': array([0.00187868, 0.00226759, 0.00267376, 0.00184083, 0.00315712,\n",
      "       0.00272986,        nan,        nan,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648, -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_DT_Lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('dtc',\n",
      "                                        DecisionTreeClassifier(random_state=42))]),\n",
      "             param_grid={'dtc__criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'dtc__max_depth': [5, 10, 15]})>\n",
      " \n",
      "predict_proba_DT_Lemma : <function BaseSearchCV.predict_proba at 0x7fa552c7f820>\n",
      " \n",
      "best_params_DT_lemma : {'dtc__criterion': 'gini', 'dtc__max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_DT_Lemma: ', grid_vect_pipe_DT_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_DT_Lemma: ', grid_vect_pipe_DT_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_DT_Lemma: ',grid_vect_pipe_DT_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_DT_Lemma :', grid_vect_pipe_DT_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_DT_lemma :', grid_vect_pipe_DT_lemma.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Tfidf + Decision Tree on Lemmatized text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.7960375 0.796575        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Decision Tree Classifier on lemmantized text + Tfidf: 0.60085\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_DT_lemma = GridSearchCV(tfidf_pipe_DT, param_grid= params_tfidf_DT)\n",
    "grid_tfidf_pipe_DT_lemma.fit(X_lemma_train, y_train)\n",
    "test_score_tfidf_DT_lemma = grid_vect_pipe_DT_lemma.score(X_lemma_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on lemmantized text + Tfidf:', test_score_tfidf_DT_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tfidf_DT_Lemma:  0.7960375000000001\n",
      " \n",
      "cv_results_tfidf_DT_Lemma:  {'mean_fit_time': array([17.39331403, 17.16291919,  0.96584253]), 'std_fit_time': array([0.33448142, 0.11615594, 0.00370483]), 'mean_score_time': array([0.25666113, 0.24981961, 0.        ]), 'std_score_time': array([0.01399089, 0.00713088, 0.        ]), 'param_dtc__criterion': masked_array(data=['gini', 'entropy', 'log_loss'],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dtc__criterion': 'gini'}, {'dtc__criterion': 'entropy'}, {'dtc__criterion': 'log_loss'}], 'split0_test_score': array([0.7925625, 0.7958125,       nan]), 'split1_test_score': array([0.79628125, 0.798     ,        nan]), 'split2_test_score': array([0.7985625 , 0.79859375,        nan]), 'split3_test_score': array([0.7964375, 0.7950625,       nan]), 'split4_test_score': array([0.79634375, 0.79540625,        nan]), 'mean_test_score': array([0.7960375, 0.796575 ,       nan]), 'std_test_score': array([0.00193724, 0.00143812,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_tfidf_DT_Lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('dtc',\n",
      "                                        DecisionTreeClassifier(random_state=42))]),\n",
      "             param_grid={'dtc__criterion': ['gini', 'entropy', 'log_loss']})>\n",
      " \n",
      "predict_proba_tfidf_DT_Lemma : <function BaseSearchCV.predict_proba at 0x7fa48dcc4c10>\n",
      " \n",
      "best_params_tfidf_DT_lemma : {'dtc__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tfidf_DT_Lemma: ', grid_tfidf_pipe_DT_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_DT_Lemma: ', grid_tfidf_pipe_DT_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_DT_Lemma: ',grid_tfidf_pipe_DT_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_DT_Lemma :', grid_tfidf_pipe_DT_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf_DT_lemma :', grid_tfidf_pipe_DT_lemma.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorize + Random Forest Classifier on Stem text with Pipeline and GridsearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_pipe_RFC = Pipeline([('vect', CountVectorizer( max_features = 1000, stop_words= 'english')),\n",
    "                          ('rfc', RandomForestClassifier())\n",
    "                           ])\n",
    "\n",
    "\n",
    "param_vect_RFC = { 'rfc__criterion': ['gini', 'entropy', 'log_loss'], \n",
    "                  'rfc__n_jobs': [1,2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83065625 0.83093125 0.83063125 0.83051875 0.833125   0.83339375\n",
      " 0.83339375 0.83368125        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(max_features=1000,\n",
       "                                                        stop_words='english')),\n",
       "                                       ('rfc', RandomForestClassifier())]),\n",
       "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'rfc__n_jobs': [1, 2, 5, 10]})"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_vect_pipe_RFC_stem = GridSearchCV(vect_pipe_RFC, param_grid= param_vect_RFC)\n",
    "grid_vect_pipe_RFC_stem.fit(X_stem_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Random Forest Classifier on Stem text + CountVectorizer: 0.83625\n"
     ]
    }
   ],
   "source": [
    "test_score_vect_RFC_stem = grid_vect_pipe_RFC_stem.score(X_stem_test, y_test)\n",
    "print('Test score: Random Forest Classifier on Stem text + CountVectorizer:', test_score_vect_RFC_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_RFC_stem:  0.83065625\n",
      " \n",
      "cv_results_RFC_stem:  {'mean_fit_time': array([319.71623297, 107.38558207,  37.58774652,  23.7258646 ,\n",
      "       170.35893054,  87.45952563,  36.68449726,  23.252424  ,\n",
      "         1.28851886,   3.06733699,   3.13025565,   3.59499063]), 'std_fit_time': array([1.78138375e+02, 3.59607784e+01, 8.81114694e-01, 9.49034278e-01,\n",
      "       1.76861816e+00, 6.07508289e-01, 9.52376734e-01, 8.19896806e-01,\n",
      "       1.39184788e-02, 2.20401073e-01, 7.16591894e-02, 8.87789190e-02]), 'mean_score_time': array([3.37415047, 1.88157434, 0.97681351, 0.76567464, 3.20777636,\n",
      "       1.81988239, 0.94949322, 0.72363472, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.0548496 , 0.05340991, 0.02810889, 0.05024164, 0.0570834 ,\n",
      "       0.07468387, 0.01435573, 0.00835839, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'param_rfc__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_rfc__n_jobs': masked_array(data=[1, 2, 5, 10, 1, 2, 5, 10, 1, 2, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 2}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 5}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 10}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 1}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 2}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 5}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 10}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 1}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 2}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 5}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 10}], 'split0_test_score': array([0.83040625, 0.830625  , 0.82953125, 0.82896875, 0.83275   ,\n",
      "       0.8335    , 0.833875  , 0.83353125,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.83259375, 0.83234375, 0.83228125, 0.8314375 , 0.836125  ,\n",
      "       0.8350625 , 0.83509375, 0.8349375 ,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.8301875 , 0.83059375, 0.83109375, 0.83121875, 0.83253125,\n",
      "       0.83284375, 0.832375  , 0.833625  ,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.8290625 , 0.82975   , 0.8296875 , 0.83040625, 0.83125   ,\n",
      "       0.8320625 , 0.83184375, 0.8320625 ,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.83103125, 0.83134375, 0.8305625 , 0.8305625 , 0.83296875,\n",
      "       0.8335    , 0.83378125, 0.83425   ,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.83065625, 0.83093125, 0.83063125, 0.83051875, 0.833125  ,\n",
      "       0.83339375, 0.83339375, 0.83368125,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.00115903, 0.00086814, 0.00100417, 0.00086616, 0.00161451,\n",
      "       0.00098813, 0.00115863, 0.00095369,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_RFC_stem:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('rfc', RandomForestClassifier())]),\n",
      "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'rfc__n_jobs': [1, 2, 5, 10]})>\n",
      " \n",
      "predict_proba_RFC_stem : <function BaseSearchCV.predict_proba at 0x7fa4e84ddc10>\n",
      " \n",
      "best_params_RFC_stem : {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_RFC_stem: ', grid_vect_pipe_RFC_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_RFC_stem: ', grid_vect_pipe_RFC_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_RFC_stem: ',grid_vect_pipe_RFC_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_RFC_stem :', grid_vect_pipe_RFC_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_RFC_stem :', grid_vect_pipe_RFC_stem.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf + Random Forest Classifier on Stem text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipe_RFC = Pipeline([('tfidf', TfidfVectorizer(max_features = 1000, stop_words= 'english')),\n",
    "                          ('rfc', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "param_tfidf_RFC = { 'rfc__criterion': ['gini', 'entropy', 'log_loss'], \n",
    "                  'rfc__n_jobs': [1,2,5,10]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83841875 0.83824375 0.83856875 0.8381875  0.8398625  0.840025\n",
      " 0.83958125 0.83958125        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.8379125  0.83815625 0.838175   0.83806875 0.83934375 0.83953125\n",
      " 0.839675   0.8397            nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Decision Tree Classifier on lemmantized text + Tfidf: 0.79065\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_RFC_stem = GridSearchCV(tfidf_pipe_RFC, param_grid= param_tfidf_RFC)\n",
    "grid_tfidf_pipe_RFC_stem.fit(X_stem_train, y_train)\n",
    "test_score_tfidf_RFC_stem = grid_tfidf_pipe_RFC_stem.fit(X_stem_train, y_train).score(X_lemma_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on lemmantized text + Tfidf:', test_score_tfidf_RFC_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tfidf_RFC_stem:  0.8379125000000001\n",
      " \n",
      "cv_results_tfidf_RFC_stem:  {'mean_fit_time': array([140.45250025,  73.90172224,  31.50893736,  19.8700695 ,\n",
      "       144.11713786,  75.67553549, 222.45520182, 205.08293481,\n",
      "         1.06569953,   2.51379042,   2.47373896,   2.85783   ]), 'std_fit_time': array([7.33671683e-01, 5.98563505e-01, 7.12743681e-01, 7.38251578e-01,\n",
      "       1.29985209e+00, 1.22535588e+00, 3.57408853e+02, 3.64686994e+02,\n",
      "       4.39632353e-02, 2.59924574e-01, 5.65009607e-03, 9.37935870e-02]), 'mean_score_time': array([2.47154565, 1.44298205, 0.75289965, 0.60675235, 2.58078265,\n",
      "       1.45500422, 0.76734905, 0.59035411, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.00941668, 0.01254161, 0.02504234, 0.02048082, 0.05987365,\n",
      "       0.03380705, 0.02047809, 0.01426659, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'param_rfc__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_rfc__n_jobs': masked_array(data=[1, 2, 5, 10, 1, 2, 5, 10, 1, 2, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 2}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 5}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 10}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 1}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 2}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 5}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 10}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 1}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 2}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 5}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 10}], 'split0_test_score': array([0.83925   , 0.8389375 , 0.8395    , 0.8393125 , 0.840625  ,\n",
      "       0.840125  , 0.8414375 , 0.84053125,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.83690625, 0.837375  , 0.83784375, 0.8365625 , 0.83990625,\n",
      "       0.83965625, 0.83965625, 0.83921875,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.8385625 , 0.8384375 , 0.83909375, 0.83890625, 0.83984375,\n",
      "       0.83921875, 0.8391875 , 0.8406875 ,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.83509375, 0.8364375 , 0.83684375, 0.83703125, 0.8371875 ,\n",
      "       0.83796875, 0.837125  , 0.8375    ,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.83975   , 0.83959375, 0.83759375, 0.83853125, 0.83915625,\n",
      "       0.8406875 , 0.84096875, 0.8405625 ,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.8379125 , 0.83815625, 0.838175  , 0.83806875, 0.83934375,\n",
      "       0.83953125, 0.839675  , 0.8397    ,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.00170562, 0.00112431, 0.00098179, 0.00107772, 0.0011741 ,\n",
      "       0.00092132, 0.00151794, 0.00122324,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_tfidf_RFC_stem:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('rfc', RandomForestClassifier())]),\n",
      "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'rfc__n_jobs': [1, 2, 5, 10]})>\n",
      " \n",
      "predict_proba_tfidf_RFC_stem : <function BaseSearchCV.predict_proba at 0x7fa48a526310>\n",
      " \n",
      "best_params_tfidf__RFC_stem : {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tfidf_RFC_stem: ', grid_tfidf_pipe_RFC_stem.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_RFC_stem: ', grid_tfidf_pipe_RFC_stem.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_RFC_stem: ',grid_tfidf_pipe_RFC_stem.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_RFC_stem :', grid_tfidf_pipe_RFC_stem.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf__RFC_stem :', grid_tfidf_pipe_RFC_stem.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorize + Random Forest Classifier on Lemmatized text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82004375 0.81975    0.8197     0.82078125 0.8232625  0.8228625\n",
      " 0.82346875 0.82379375        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(max_features=1000,\n",
       "                                                        stop_words='english')),\n",
       "                                       ('rfc', RandomForestClassifier())]),\n",
       "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'rfc__n_jobs': [1, 2, 5, 10]})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_vect_pipe_RFC_lemma = GridSearchCV(vect_pipe_RFC, param_grid= param_vect_RFC)\n",
    "grid_vect_pipe_RFC_lemma.fit(X_lemma_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Random Forest Classifier on lemmatized text + CountVectorizer: 0.83625\n"
     ]
    }
   ],
   "source": [
    "grid_vect_pipe_RFC_lemma.score(X_lemma_test, y_test)\n",
    "print('Test score: Random Forest Classifier on lemmatized text + CountVectorizer:', test_score_vect_RFC_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_RFC_lemma:  0.8201124999999999\n",
      " \n",
      "cv_results_RFC_lemma:  {'mean_fit_time': array([162.83813338,  84.36173062,  35.42500658,  22.09844961,\n",
      "       217.64355721,  82.61667848,  34.65750914,  21.92023978,\n",
      "         1.36544604,   3.27338338,   3.30593739,   3.9070004 ]), 'std_fit_time': array([5.41588404e-01, 5.71412229e-01, 8.96745648e-01, 1.24160422e+00,\n",
      "       7.02675278e+01, 9.16624685e-01, 8.35294365e-01, 4.43151889e-01,\n",
      "       6.66687922e-02, 2.63099918e-01, 9.01955743e-02, 2.42789820e-01]), 'mean_score_time': array([3.66975856, 2.01393967, 1.08475819, 0.80479031, 3.64413738,\n",
      "       1.93968697, 0.97585382, 0.75836082, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.05698716, 0.02804092, 0.0700268 , 0.04098161, 0.04566177,\n",
      "       0.03301177, 0.03069398, 0.06721933, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'param_rfc__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_rfc__n_jobs': masked_array(data=[1, 2, 5, 10, 1, 2, 5, 10, 1, 2, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 2}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 5}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 10}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 1}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 2}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 5}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 10}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 1}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 2}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 5}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 10}], 'split0_test_score': array([0.81759375, 0.81740625, 0.8175    , 0.818875  , 0.82140625,\n",
      "       0.821125  , 0.8210625 , 0.82115625,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.82121875, 0.82215625, 0.821125  , 0.82090625, 0.8249375 ,\n",
      "       0.82415625, 0.82515625, 0.825     ,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.82146875, 0.820125  , 0.82109375, 0.82171875, 0.825125  ,\n",
      "       0.824875  , 0.825     , 0.8249375 ,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.818625  , 0.8178125 , 0.81925   , 0.81865625, 0.82253125,\n",
      "       0.821375  , 0.82228125, 0.821375  ,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.82165625, 0.8210625 , 0.8211875 , 0.82146875, 0.8250625 ,\n",
      "       0.82465625, 0.824375  , 0.825125  ,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.8201125 , 0.8197125 , 0.82003125, 0.820325  , 0.8238125 ,\n",
      "       0.8232375 , 0.823575  , 0.82351875,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.00167351, 0.00183812, 0.00146148, 0.00130198, 0.00154806,\n",
      "       0.00164134, 0.00162219, 0.00184196,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_RFC_lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
      "                                        CountVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('rfc', RandomForestClassifier())]),\n",
      "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'rfc__n_jobs': [1, 2, 5, 10]})>\n",
      " \n",
      "predict_proba_RFC_lemma : <function BaseSearchCV.predict_proba at 0x7fa575de5820>\n",
      " \n",
      "best_params_RFC_lemma : {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_RFC_lemma: ', grid_vect_pipe_RFC_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_RFC_lemma: ', grid_vect_pipe_RFC_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_RFC_lemma: ',grid_vect_pipe_RFC_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_RFC_lemma :', grid_vect_pipe_RFC_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_RFC_lemma :', grid_vect_pipe_RFC_lemma.best_params_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Tfidf + Random Forest Classifier on Lemmantized text with Pipeline and GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82853125 0.82883125 0.828725   0.82906875 0.83064375 0.82980625\n",
      " 0.829875   0.830325          nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82870625 0.82895    0.8287     0.82848125 0.82996875 0.83030625\n",
      " 0.829875   0.82998125        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: Decision Tree Classifier on lemmantized text + Tfidf: 0.834325\n"
     ]
    }
   ],
   "source": [
    "grid_tfidf_pipe_RFC_lemma = GridSearchCV(tfidf_pipe_RFC, param_grid= param_tfidf_RFC)\n",
    "grid_tfidf_pipe_RFC_lemma.fit(X_lemma_train, y_train)\n",
    "test_score_tfidf_RFC_lemma = grid_tfidf_pipe_RFC_lemma.fit(X_lemma_train, y_train).score(X_lemma_test, y_test)\n",
    "\n",
    "print('Test score: Decision Tree Classifier on lemmantized text + Tfidf:', test_score_tfidf_RFC_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score_tfidf_RFC_lemma:  0.82870625\n",
      " \n",
      "cv_results_tfidf_RFC_lemma:  {'mean_fit_time': array([708.03427825, 626.61444545, 424.41285996, 114.26163349,\n",
      "       873.27211375,  74.7644455 , 281.33600974, 403.80933499,\n",
      "         1.01472926,   2.46250696,   2.54475303,   2.83853884]), 'std_fit_time': array([4.04737149e+02, 4.53186336e+02, 4.82295889e+02, 1.18729421e+02,\n",
      "       4.27222336e+02, 9.49557483e-01, 3.64418178e+02, 4.69748393e+02,\n",
      "       5.16259644e-02, 1.05164244e-01, 4.22225737e-02, 3.62872316e-02]), 'mean_score_time': array([2.80669322, 1.71330171, 0.80729403, 0.64736476, 2.88351564,\n",
      "       1.63491554, 0.83855925, 0.74726415, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'std_score_time': array([0.03096762, 0.27353339, 0.02372289, 0.04223033, 0.06189575,\n",
      "       0.03547313, 0.01222378, 0.14049374, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), 'param_rfc__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_rfc__n_jobs': masked_array(data=[1, 2, 5, 10, 1, 2, 5, 10, 1, 2, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 2}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 5}, {'rfc__criterion': 'gini', 'rfc__n_jobs': 10}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 1}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 2}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 5}, {'rfc__criterion': 'entropy', 'rfc__n_jobs': 10}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 1}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 2}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 5}, {'rfc__criterion': 'log_loss', 'rfc__n_jobs': 10}], 'split0_test_score': array([0.8265    , 0.82684375, 0.8274375 , 0.8256875 , 0.828375  ,\n",
      "       0.828     , 0.8271875 , 0.82778125,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.83      , 0.8295    , 0.82828125, 0.82925   , 0.83175   ,\n",
      "       0.8316875 , 0.830875  , 0.83146875,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.8295    , 0.8294375 , 0.8306875 , 0.830625  , 0.83184375,\n",
      "       0.83184375, 0.83225   , 0.8309375 ,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.8265    , 0.82671875, 0.82628125, 0.82628125, 0.82603125,\n",
      "       0.8284375 , 0.82709375, 0.82784375,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.83103125, 0.83225   , 0.8308125 , 0.8305625 , 0.83184375,\n",
      "       0.8315625 , 0.83196875, 0.831875  ,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.82870625, 0.82895   , 0.8287    , 0.82848125, 0.82996875,\n",
      "       0.83030625, 0.829875  , 0.82998125,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.00186786, 0.00204181, 0.00179067, 0.00210539, 0.00237689,\n",
      "       0.00171236, 0.00227958, 0.00179568,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648, -2147483648, -2147483648, -2147483648,\n",
      "       -2147483648, -2147483648], dtype=int32)}\n",
      " \n",
      "get_params_tfidf_RFC_lemma:  <bound method BaseEstimator.get_params of GridSearchCV(estimator=Pipeline(steps=[('tfidf',\n",
      "                                        TfidfVectorizer(max_features=1000,\n",
      "                                                        stop_words='english')),\n",
      "                                       ('rfc', RandomForestClassifier())]),\n",
      "             param_grid={'rfc__criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'rfc__n_jobs': [1, 2, 5, 10]})>\n",
      " \n",
      "predict_proba_tfidf_RFC_lemma : <function BaseSearchCV.predict_proba at 0x7fa3793f50d0>\n",
      " \n",
      "best_params_tfidf__RFC_lemma : {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}\n"
     ]
    }
   ],
   "source": [
    "print('best_score_tfidf_RFC_lemma: ', grid_tfidf_pipe_RFC_lemma.best_score_)\n",
    "print(\" \")\n",
    "print('cv_results_tfidf_RFC_lemma: ', grid_tfidf_pipe_RFC_lemma.cv_results_)\n",
    "print(\" \")\n",
    "print('get_params_tfidf_RFC_lemma: ',grid_tfidf_pipe_RFC_lemma.get_params)\n",
    "print(\" \")\n",
    "print('predict_proba_tfidf_RFC_lemma :', grid_tfidf_pipe_RFC_lemma.predict_proba)\n",
    "print(\" \")\n",
    "print('best_params_tfidf__RFC_lemma :', grid_tfidf_pipe_RFC_lemma.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed Text</th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>Cross Validation Results</th>\n",
       "      <th>Predict Proba</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Logistic Regression - Stem</td>\n",
       "      <td>0.837275</td>\n",
       "      <td>{'mean_fit_time': [1.0618602275848388, 1.06010...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'logi__C': 1.0, 'logi__penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Logistic Regression - Lemma</td>\n",
       "      <td>0.829381</td>\n",
       "      <td>{'mean_fit_time': [1.1201605796813965, 1.16496...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'logi__C': 100.0, 'logi__penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Decision Tree - Stem</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>{'mean_fit_time': [17.94860601425171, 20.33583...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'dtc__criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Decision Tree - Lemma</td>\n",
       "      <td>0.602275</td>\n",
       "      <td>{'mean_fit_time': [1.101417064666748, 1.168362...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>RandomForestClassifier - Stem</td>\n",
       "      <td>0.830656</td>\n",
       "      <td>{'mean_fit_time': [319.7162329673767, 107.3855...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>RandomForestClassifier - Lemma</td>\n",
       "      <td>0.820044</td>\n",
       "      <td>{'mean_fit_time': [519.6760025024414, 678.1045...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stemmed Text                           Model   Best Scores  \\\n",
       "0                   Logistic Regression - Stem      0.837275   \n",
       "1                  Logistic Regression - Lemma      0.829381   \n",
       "2                         Decision Tree - Stem      0.790600   \n",
       "3                        Decision Tree - Lemma      0.602275   \n",
       "4                RandomForestClassifier - Stem      0.830656   \n",
       "5               RandomForestClassifier - Lemma      0.820044   \n",
       "\n",
       "                            Cross Validation Results  \\\n",
       "0  {'mean_fit_time': [1.0618602275848388, 1.06010...   \n",
       "1  {'mean_fit_time': [1.1201605796813965, 1.16496...   \n",
       "2  {'mean_fit_time': [17.94860601425171, 20.33583...   \n",
       "3  {'mean_fit_time': [1.101417064666748, 1.168362...   \n",
       "4  {'mean_fit_time': [319.7162329673767, 107.3855...   \n",
       "5  {'mean_fit_time': [519.6760025024414, 678.1045...   \n",
       "\n",
       "                                       Predict Proba  \\\n",
       "0  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "1  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "2  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "3  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "4  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "5  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "\n",
       "                                   Best Parameters  \n",
       "0          {'logi__C': 1.0, 'logi__penalty': 'l2'}  \n",
       "1        {'logi__C': 100.0, 'logi__penalty': 'l2'}  \n",
       "2                       {'dtc__criterion': 'gini'}  \n",
       "3  {'dtc__criterion': 'gini', 'dtc__max_depth': 5}  \n",
       "4     {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}  \n",
       "5     {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary_CV = pd. DataFrame({'Stemmed Text':  ' ',\n",
    "                            'Model': [ 'Logistic Regression - Stem', 'Logistic Regression - Lemma', 'Decision Tree - Stem', 'Decision Tree - Lemma', 'RandomForestClassifier - Stem', 'RandomForestClassifier - Lemma'], \n",
    "                         ' Best Scores': [grid_vect_pipe_logi_stem.best_score_, grid_vect_pipe_LR_lemma.best_score_, grid_vect_pipe_DT_stem.best_score_, grid_vect_pipe_DT_lemma.best_score_, grid_vect_pipe_RFC_stem.best_score_, grid_vect_pipe_RFC_lemma.best_score_],\n",
    "                         'Cross Validation Results': [grid_vect_pipe_logi_stem.cv_results_, grid_vect_pipe_LR_lemma.cv_results_, grid_vect_pipe_DT_stem.cv_results_, grid_vect_pipe_DT_lemma.cv_results_, grid_vect_pipe_RFC_stem.cv_results_, grid_vect_pipe_RFC_lemma.cv_results_],\n",
    "                         'Predict Proba': [grid_vect_pipe_logi_stem.predict_proba, grid_vect_pipe_LR_lemma.predict_proba, grid_vect_pipe_DT_stem.predict_proba, grid_vect_pipe_DT_lemma.predict_proba, grid_vect_pipe_RFC_stem.predict_proba, grid_vect_pipe_RFC_lemma.predict_proba],\n",
    "                         'Best Parameters':[grid_vect_pipe_logi_stem.best_params_, grid_vect_pipe_LR_lemma.best_params_, grid_vect_pipe_DT_stem.best_params_, grid_vect_pipe_DT_lemma.best_params_, grid_vect_pipe_RFC_stem.best_params_, grid_vect_pipe_RFC_lemma.best_params_]\n",
    "                         })\n",
    "Summary_CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results - Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmanzited</th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>Cross Validation Results</th>\n",
       "      <th>Predict Proba</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Logistic Regression - Stem</td>\n",
       "      <td>0.840394</td>\n",
       "      <td>{'mean_fit_time': [1.0713510036468505, 1.04827...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'logi__C': 10.0, 'logi__penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Logistic Regression - Lemma</td>\n",
       "      <td>0.830075</td>\n",
       "      <td>{'mean_fit_time': [1.034341526031494, 1.102467...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'logi__C': 10.0, 'logi__penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Decision Tree - Stem</td>\n",
       "      <td>0.801244</td>\n",
       "      <td>{'mean_fit_time': [19.55327625274658, 19.16711...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'dtc__criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Decision Tree - Lemma</td>\n",
       "      <td>0.796038</td>\n",
       "      <td>{'mean_fit_time': [17.393314027786253, 17.1629...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'dtc__criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>RandomForestClassifier - Stem</td>\n",
       "      <td>0.837913</td>\n",
       "      <td>{'mean_fit_time': [140.45250024795533, 73.9017...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>RandomForestClassifier - Lemma</td>\n",
       "      <td>0.828706</td>\n",
       "      <td>{'mean_fit_time': [708.0342782497406, 626.6144...</td>\n",
       "      <td>&lt;function BaseSearchCV.predict_proba at 0x7fa3...</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_jobs': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lemmanzited                           Model   Best Scores  \\\n",
       "0                  Logistic Regression - Stem      0.840394   \n",
       "1                 Logistic Regression - Lemma      0.830075   \n",
       "2                        Decision Tree - Stem      0.801244   \n",
       "3                       Decision Tree - Lemma      0.796038   \n",
       "4               RandomForestClassifier - Stem      0.837913   \n",
       "5              RandomForestClassifier - Lemma      0.828706   \n",
       "\n",
       "                            Cross Validation Results  \\\n",
       "0  {'mean_fit_time': [1.0713510036468505, 1.04827...   \n",
       "1  {'mean_fit_time': [1.034341526031494, 1.102467...   \n",
       "2  {'mean_fit_time': [19.55327625274658, 19.16711...   \n",
       "3  {'mean_fit_time': [17.393314027786253, 17.1629...   \n",
       "4  {'mean_fit_time': [140.45250024795533, 73.9017...   \n",
       "5  {'mean_fit_time': [708.0342782497406, 626.6144...   \n",
       "\n",
       "                                       Predict Proba  \\\n",
       "0  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "1  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "2  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "3  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "4  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "5  <function BaseSearchCV.predict_proba at 0x7fa3...   \n",
       "\n",
       "                                Best Parameters  \n",
       "0      {'logi__C': 10.0, 'logi__penalty': 'l2'}  \n",
       "1      {'logi__C': 10.0, 'logi__penalty': 'l1'}  \n",
       "2                    {'dtc__criterion': 'gini'}  \n",
       "3                    {'dtc__criterion': 'gini'}  \n",
       "4  {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}  \n",
       "5  {'rfc__criterion': 'gini', 'rfc__n_jobs': 1}  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary_Tfidf = pd. DataFrame({'Lemmanzited': ' ', \n",
    "                               'Model': [ 'Logistic Regression - Stem', 'Logistic Regression - Lemma', 'Decision Tree - Stem', 'Decision Tree - Lemma', 'RandomForestClassifier - Stem', 'RandomForestClassifier - Lemma'], \n",
    "                               ' Best Scores': [grid_tfidf_pipe_logi_stem.best_score_, grid_tfidf_pipe_logi_lemma.best_score_, grid_tfidf_pipe_DT_stem.best_score_, grid_tfidf_pipe_DT_lemma.best_score_, grid_tfidf_pipe_RFC_stem.best_score_, grid_tfidf_pipe_RFC_lemma.best_score_],\n",
    "                               'Cross Validation Results': [grid_tfidf_pipe_logi_stem.cv_results_, grid_tfidf_pipe_logi_lemma.cv_results_, grid_tfidf_pipe_DT_stem.cv_results_, grid_tfidf_pipe_DT_lemma.cv_results_, grid_tfidf_pipe_RFC_stem.cv_results_, grid_tfidf_pipe_RFC_lemma.cv_results_],\n",
    "                               'Predict Proba': [grid_tfidf_pipe_logi_stem.predict_proba, grid_tfidf_pipe_logi_lemma.predict_proba, grid_tfidf_pipe_DT_stem.predict_proba, grid_tfidf_pipe_DT_lemma.predict_proba, grid_tfidf_pipe_RFC_stem.predict_proba, grid_tfidf_pipe_RFC_lemma.predict_proba],\n",
    "                               'Best Parameters':[grid_tfidf_pipe_logi_stem.best_params_, grid_tfidf_pipe_logi_lemma.best_params_, grid_tfidf_pipe_DT_stem.best_params_, grid_tfidf_pipe_DT_lemma.best_params_, grid_tfidf_pipe_RFC_stem.best_params_, grid_tfidf_pipe_RFC_lemma.best_params_]\n",
    "                         })\n",
    "\n",
    "Summary_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
